{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN - Example 3\n",
    "This code is from \"Python - All in One for Dummies\"\n",
    "\n",
    "This example uses Fashion_MNIST dataset and predicts a given image using CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Fashion_MNIST data set\n",
    "# https://github.com/zalandoresearch/fashion-mnist \n",
    "# the images are 28x28 and grayscale\n",
    "# there are 60,000 training images and 10,000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-b1ac18e0167f>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\cenker\\.conda\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\cenker\\.conda\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../cnn_example3_data/fashion\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\cenker\\.conda\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../cnn_example3_data/fashion\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\cenker\\.conda\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../cnn_example3_data/fashion\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../cnn_example3_data/fashion\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\cenker\\.conda\\envs\\python-cvcourse\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# Import Fashion MNIST\n",
    "# note that onehotencoding is performed\n",
    "# if you do not have the correct path, it downloads regular MNIST and not fashion dataset ?\n",
    "fashion_mnist = input_data.read_data_sets('../cnn_example3_data/fashion', one_hot=True)\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# setup training and test datasets\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let us see the dimensions of one of the images\n",
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let us see the pixel values for one of the images\n",
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the images are gray-scale. We will normalize the values to [0-1]\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the training images, adding color dimension (1=grayscale)\n",
    "train_images = train_images.reshape(train_images.shape[0],28,28,1)\n",
    "\n",
    "# prepare the test images,adding color dimension (1=grayscale)\n",
    "test_images = test_images.reshape(test_images.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set descriptive names to the ten classes within the Fashion_MNIST data.\n",
    "class_names = ['T-shirt/top', 'Trouser','Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we do not need to convert test and training labels to one-hot-encoded form\n",
    "# since we read the data in with the one_hot = True\n",
    "# from keras.utils import to_categorical\n",
    "# train_labels_cat = to_categorical(train_labels)\n",
    "# test_labels_cat = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the CNN model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# they are 28x28 images\n",
    "input_shape = (28,28,1)\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# compile the model\n",
    "# Sparse categorical crossentropy is a loss function used to measure the error between categories across the data set. \n",
    "# Categorical refers to the fact that the data has more than two categories (binary) in the data set. \n",
    "# Sparse refers to using a single integer to refer to classes (0â€“9, in our example). \n",
    "# Entropy (a measure of disorder) refers to the mix of data between the categories.\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,221,546\n",
      "Trainable params: 1,219,754\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 299s 5ms/step - loss: 0.6046 - acc: 0.7863\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 300s 5ms/step - loss: 0.3811 - acc: 0.8639\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 309s 5ms/step - loss: 0.3445 - acc: 0.8790\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 319s 5ms/step - loss: 0.3115 - acc: 0.8910\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 318s 5ms/step - loss: 0.2968 - acc: 0.8956\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history = model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "accuracy = history.history['acc']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.figure(0)\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, accuracy, 'b--')\n",
    "plt.legend(['Training Loss', 'Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('History')\n",
    "plt.show(block=False);\n",
    "plt.pause(0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 20s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model, test with 10,000 images to calculate the model score\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26514259245991706"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.905"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.84      0.86      1000\n",
      "          1       0.99      0.98      0.99      1000\n",
      "          2       0.82      0.91      0.86      1000\n",
      "          3       0.88      0.93      0.91      1000\n",
      "          4       0.88      0.77      0.82      1000\n",
      "          5       0.99      0.96      0.97      1000\n",
      "          6       0.72      0.74      0.73      1000\n",
      "          7       0.93      0.98      0.96      1000\n",
      "          8       0.98      0.97      0.98      1000\n",
      "          9       0.98      0.96      0.97      1000\n",
      "\n",
      "avg / total       0.91      0.91      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predictions = model.predict_classes(test_images)\n",
    "print(classification_report(test_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will test the model using a single test image from Fashion_MNIST dataset\n",
    "# get a test image from Fashion_MNIST data\n",
    "img = test_images[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall that the pixel values for this test image were already scaled [0-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "# to display using imshow() we will create a temp copy with dimensions of (28x28)\n",
    "plt.imshow(img.reshape(28,28), cmap='gray')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the predict() method expects the image in 4 dimensions. The 4th dimension is a batch.\n",
    "# So we have one batch that consists of one image here. \n",
    "img = (np.expand_dims(img,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Output\n",
      "[[4.8053066e-06 9.9994457e-01 2.7748749e-06 3.5689052e-05 5.3130530e-06\n",
      "  2.1097527e-07 5.2220093e-06 3.1524866e-07 8.8093259e-07 2.5085541e-07]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "singlePrediction = model.predict(img,steps=1)\n",
    "print (\"Prediction Output\")\n",
    "print(singlePrediction)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the prediction returns different probabilities for each class in class_names[]\n",
    "# the largest probability is the prediction of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Network has concluded that the image number '15' is a Trouser\n",
      "99% Confidence Level\n",
      "Test accuracy 0.905\n"
     ]
    }
   ],
   "source": [
    "# get the index (element) with the hightest probability\n",
    "NumberElement = singlePrediction.argmax()\n",
    "# get the probability value itself\n",
    "Element = np.amax(singlePrediction)\n",
    "\n",
    "print (\"Our Network has concluded that the image number '15' is a \" +class_names[NumberElement])\n",
    "print (str(int(Element*100)) + \"% Confidence Level\")\n",
    "print('Test accuracy', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# now we will use an external image to test the model\n",
    "# read test image and force it to 28x28 resolution\n",
    "\n",
    "imageName = \"cnn_example3_data/tshirt_white.jpg\"\n",
    "from keras.preprocessing import image\n",
    "testImg = image.load_img(imageName, target_size=(28, 28),color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the image\n",
    "plt.imshow(testImg, cmap='gray')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to array\n",
    "testImg = image.img_to_array(testImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testImg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the pixel values to [0-1] excluding color dimension\n",
    "testImg[0] = testImg[0]/255\n",
    "testImg[1] = testImg[1]/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the predict() method expects the image in 4 dimensions. The 4th dimension is a batch.\n",
    "# So we have one batch that consists of one image here. \n",
    "testImg = (np.expand_dims(testImg,axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testImg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "singlePrediction = model.predict(testImg,steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Output\n",
      "[[9.7264037e-09 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.9999988e-01\n",
      "  0.0000000e+00 1.3182013e-07 0.0000000e+00 1.9040594e-10 0.0000000e+00]]\n",
      "\n",
      "Our Network has concluded that the file 'cnn_example3_data/tshirt_white.jpg' is a Coat\n",
      "99% Confidence Level\n"
     ]
    }
   ],
   "source": [
    "print (\"Prediction Output\")\n",
    "print(singlePrediction)\n",
    "print()\n",
    "\n",
    "NumberElement = singlePrediction.argmax()\n",
    "Element = np.amax(singlePrediction)\n",
    "print (\"Our Network has concluded that the file '\" +imageName+\"' is a \"+class_names[NumberElement])\n",
    "print (str(int(Element*100)) + \"% Confidence Level\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
