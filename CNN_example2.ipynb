{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN) Example 2\n",
    "This example is from the Udemy course titled \"Deep Learning A-Z - Handson ANNs\"\n",
    "It is the result of the competition among students.\n",
    "The article can be found here: https://www.udemy.com/course/deeplearning/learn/lecture/7023358#questions/2276518 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "from tensorflow.contrib.keras.api.keras.layers import Dropout\n",
    "from tensorflow.contrib.keras.api.keras.models import Sequential\n",
    "from tensorflow.contrib.keras.api.keras.layers import Conv2D\n",
    "from tensorflow.contrib.keras.api.keras.layers import MaxPooling2D\n",
    "from tensorflow.contrib.keras.api.keras.layers import Flatten\n",
    "from tensorflow.contrib.keras.api.keras.layers import Dense\n",
    "from tensorflow.contrib.keras.api.keras.callbacks import Callback\n",
    "from tensorflow.contrib.keras.api.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.contrib.keras import backend\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.epoch_id = 0\n",
    "        self.losses = ''\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses += \"Epoch {}: accuracy -> {:.4f}, val_accuracy -> {:.4f}\\n\"\\\n",
    "            .format(str(self.epoch_id), logs.get('acc'), logs.get('val_acc'))\n",
    "        self.epoch_id += 1\n",
    " \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses += 'Training begins...\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directories\n",
    "script_dir = os.getcwd()\n",
    "training_set_path = script_dir + \"/cnn_example1_dataset/training_set\"\n",
    "test_set_path = script_dir + \"/cnn_example1_dataset/test_set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    " \n",
    "# Step 1 - Convolution\n",
    "input_size = (128, 128)\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(*input_size, 3), activation='relu'))\n",
    " \n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))  # 2x2 is optimal\n",
    " \n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "# Adding a third convolutional layer\n",
    "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    " \n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units=64, activation='relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Part 2 - Fitting the CNN to the images\n",
    "batch_size = 32\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    " \n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    " \n",
    "training_set = train_datagen.flow_from_directory(training_set_path,\n",
    "                                                 target_size=input_size,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode='binary')\n",
    " \n",
    "test_set = test_datagen.flow_from_directory(test_set_path,\n",
    "                                            target_size=input_size,\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "250/250 [==============================] - 90s 360ms/step - loss: 0.6720 - acc: 0.5813 - val_loss: 0.6003 - val_acc: 0.6895\n",
      "Epoch 2/30\n",
      "250/250 [==============================] - 89s 356ms/step - loss: 0.6000 - acc: 0.6720 - val_loss: 0.5778 - val_acc: 0.7005\n",
      "Epoch 3/30\n",
      "250/250 [==============================] - 85s 340ms/step - loss: 0.5665 - acc: 0.7137 - val_loss: 0.5156 - val_acc: 0.7565\n",
      "Epoch 4/30\n",
      "250/250 [==============================] - 87s 348ms/step - loss: 0.5215 - acc: 0.7424 - val_loss: 0.5051 - val_acc: 0.7600\n",
      "Epoch 5/30\n",
      "250/250 [==============================] - 85s 342ms/step - loss: 0.5038 - acc: 0.7624 - val_loss: 0.4608 - val_acc: 0.7855\n",
      "Epoch 6/30\n",
      "250/250 [==============================] - 90s 358ms/step - loss: 0.4792 - acc: 0.7755 - val_loss: 0.4801 - val_acc: 0.7735\n",
      "Epoch 7/30\n",
      "250/250 [==============================] - 87s 346ms/step - loss: 0.4619 - acc: 0.7833 - val_loss: 0.4812 - val_acc: 0.7815\n",
      "Epoch 8/30\n",
      "250/250 [==============================] - 75s 302ms/step - loss: 0.4484 - acc: 0.7980 - val_loss: 0.4212 - val_acc: 0.8070\n",
      "Epoch 9/30\n",
      "250/250 [==============================] - 73s 290ms/step - loss: 0.4268 - acc: 0.8077 - val_loss: 0.4503 - val_acc: 0.7965\n",
      "Epoch 10/30\n",
      "250/250 [==============================] - 66s 264ms/step - loss: 0.4138 - acc: 0.8212 - val_loss: 0.4718 - val_acc: 0.7865\n",
      "Epoch 11/30\n",
      "250/250 [==============================] - 66s 266ms/step - loss: 0.4070 - acc: 0.8212 - val_loss: 0.4153 - val_acc: 0.8245\n",
      "Epoch 12/30\n",
      "250/250 [==============================] - 68s 270ms/step - loss: 0.3883 - acc: 0.8267 - val_loss: 0.4065 - val_acc: 0.8220\n",
      "Epoch 13/30\n",
      "250/250 [==============================] - 75s 301ms/step - loss: 0.3749 - acc: 0.8350 - val_loss: 0.4104 - val_acc: 0.8270\n",
      "Epoch 14/30\n",
      "250/250 [==============================] - 84s 337ms/step - loss: 0.3565 - acc: 0.8408 - val_loss: 0.4038 - val_acc: 0.8315\n",
      "Epoch 15/30\n",
      "250/250 [==============================] - 74s 294ms/step - loss: 0.3524 - acc: 0.8441 - val_loss: 0.3954 - val_acc: 0.8305\n",
      "Epoch 16/30\n",
      "250/250 [==============================] - 69s 277ms/step - loss: 0.3423 - acc: 0.8541 - val_loss: 0.4147 - val_acc: 0.8175\n",
      "Epoch 17/30\n",
      "250/250 [==============================] - 80s 319ms/step - loss: 0.3351 - acc: 0.8565 - val_loss: 0.4173 - val_acc: 0.8190\n",
      "Epoch 18/30\n",
      "250/250 [==============================] - 69s 275ms/step - loss: 0.3258 - acc: 0.8591 - val_loss: 0.3688 - val_acc: 0.8450\n",
      "Epoch 19/30\n",
      "250/250 [==============================] - 70s 281ms/step - loss: 0.3187 - acc: 0.8634 - val_loss: 0.3799 - val_acc: 0.8370\n",
      "Epoch 20/30\n",
      "250/250 [==============================] - 69s 276ms/step - loss: 0.2939 - acc: 0.8741 - val_loss: 0.4277 - val_acc: 0.8340\n",
      "Epoch 21/30\n",
      "250/250 [==============================] - 70s 279ms/step - loss: 0.2951 - acc: 0.8744 - val_loss: 0.3834 - val_acc: 0.8525\n",
      "Epoch 22/30\n",
      "250/250 [==============================] - 72s 289ms/step - loss: 0.2943 - acc: 0.8774 - val_loss: 0.3875 - val_acc: 0.8530\n",
      "Epoch 23/30\n",
      "250/250 [==============================] - 78s 312ms/step - loss: 0.2842 - acc: 0.8801 - val_loss: 0.3666 - val_acc: 0.8610\n",
      "Epoch 24/30\n",
      "250/250 [==============================] - 72s 289ms/step - loss: 0.2766 - acc: 0.8806 - val_loss: 0.3749 - val_acc: 0.8600\n",
      "Epoch 25/30\n",
      "250/250 [==============================] - 93s 372ms/step - loss: 0.2641 - acc: 0.8861 - val_loss: 0.3696 - val_acc: 0.8620\n",
      "Epoch 26/30\n",
      "250/250 [==============================] - 89s 357ms/step - loss: 0.2586 - acc: 0.8894 - val_loss: 0.3520 - val_acc: 0.8615\n",
      "Epoch 27/30\n",
      "250/250 [==============================] - 88s 350ms/step - loss: 0.2588 - acc: 0.8931 - val_loss: 0.3605 - val_acc: 0.8620\n",
      "Epoch 28/30\n",
      "250/250 [==============================] - 95s 379ms/step - loss: 0.2472 - acc: 0.8965 - val_loss: 0.3693 - val_acc: 0.8605\n",
      "Epoch 29/30\n",
      "250/250 [==============================] - 86s 344ms/step - loss: 0.2479 - acc: 0.8941 - val_loss: 0.3496 - val_acc: 0.8660\n",
      "Epoch 30/30\n",
      "250/250 [==============================] - 92s 369ms/step - loss: 0.2469 - acc: 0.8967 - val_loss: 0.3761 - val_acc: 0.8670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x218d2eae198>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a loss history\n",
    "history = LossHistory()\n",
    " \n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch=8000/batch_size,\n",
    "                         epochs=30,\n",
    "                         validation_data=test_set,\n",
    "                         validation_steps=2000/batch_size,\n",
    "                         workers=12,\n",
    "#                         max_q_size=100,\n",
    "                         callbacks=[history])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\cenker\\OneDrive\\Desktop\\Docs\\Personal\\Data_Science\\Deep_Learning\\Python_ML_Examples/cnn_example1_dataset/cat_or_dogs_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "# model_backup_path = os.path.join(script_dir, '/cnn_example1_dataset/cat_or_dogs_model.h5')\n",
    "model_backup_path = script_dir + \"/cnn_example1_dataset/cat_or_dogs_model.h5\"\n",
    "classifier.save(model_backup_path)\n",
    "print(\"Model saved to\", model_backup_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save loss history to file\n",
    "# loss_history_path = os.path.join(script_dir, '/cnn_example1_dataset/loss_history.log')\n",
    "loss_history_path = script_dir + \"/cnn_example1_dataset/loss_history.log\"\n",
    "myFile = open(loss_history_path, 'w+')\n",
    "myFile.write(history.losses)\n",
    "myFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model class indices are: {'cats': 0, 'dogs': 1}\n"
     ]
    }
   ],
   "source": [
    "backend.clear_session()\n",
    "print(\"The model class indices are:\", training_set.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
